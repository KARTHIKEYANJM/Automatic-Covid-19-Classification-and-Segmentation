{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU') \n",
    "from tensorflow.keras.applications import VGG16,InceptionV3\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout,Flatten, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix,plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import itertools\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D, Add, Activation, Multiply, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='../input/newdataset/final_dataset/train'\n",
    "test_path='../input/newdataset/final_dataset/test'\n",
    "val_path='../input/newdataset/final_dataset/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5402 images belonging to 2 classes.\n",
      "Found 650 images belonging to 2 classes.\n",
      "Found 26 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_path,target_size = (320, 320),shuffle=True,seed=42,class_mode=\"categorical\",color_mode = 'rgb',batch_size = 16)\n",
    "test_generator = test_datagen.flow_from_directory(test_path,target_size = (320, 320),color_mode = 'rgb',batch_size = 1,seed=42,class_mode=\"categorical\",shuffle = False)\n",
    "val_generator = test_datagen.flow_from_directory(val_path,target_size = (320, 320),color_mode = 'rgb',batch_size = 1,seed=42,class_mode=\"categorical\",shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basemodel = InceptionV3(weights='imagenet', include_top=False,input_tensor=Input(shape=(320, 320, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = basemodel.output\n",
    "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)#pool_size=(4, 4)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.3)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=basemodel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 320, 320, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 159, 159, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 159, 159, 32) 96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 159, 159, 32) 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 157, 157, 32) 9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 157, 157, 32) 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 157, 157, 32) 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 157, 157, 64) 18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 157, 157, 64) 192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 157, 157, 64) 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 78, 78, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 78, 78, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 78, 78, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 78, 78, 80)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 76, 76, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 76, 76, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 76, 76, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 37, 37, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 37, 37, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 37, 37, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 37, 37, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 37, 37, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 37, 37, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 37, 37, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 37, 37, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 37, 37, 48)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 37, 37, 96)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 37, 37, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 37, 37, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 37, 37, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 37, 37, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 37, 37, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 37, 37, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 37, 37, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 37, 37, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 37, 37, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 37, 37, 64)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 37, 37, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 37, 37, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 37, 37, 32)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 37, 37, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 37, 37, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 37, 37, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 37, 37, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 37, 37, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 37, 37, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 37, 37, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 37, 37, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 37, 37, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 37, 37, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 37, 37, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 37, 37, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 37, 37, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 37, 37, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 37, 37, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 37, 37, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 37, 37, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 37, 37, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 37, 37, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 37, 37, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 37, 37, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 37, 37, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 37, 37, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 37, 37, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 37, 37, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 37, 37, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 37, 37, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 37, 37, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 37, 37, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 37, 37, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 37, 37, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 37, 37, 48)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 37, 37, 96)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 37, 37, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 37, 37, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 37, 37, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 37, 37, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 37, 37, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 37, 37, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 37, 37, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 37, 37, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 37, 37, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 37, 37, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 37, 37, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 37, 37, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 37, 37, 64)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 37, 37, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 37, 37, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 37, 37, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 37, 37, 64)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 37, 37, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 37, 37, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 37, 37, 96)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 18, 18, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 18, 18, 96)   82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 18, 18, 384)  1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 18, 18, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 18, 18, 384)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 18, 18, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 18, 18, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 18, 18, 768)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 18, 18, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 18, 18, 128)  384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 18, 18, 128)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 18, 18, 128)  114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 18, 18, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 18, 18, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 18, 18, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 18, 18, 128)  114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 18, 18, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 18, 18, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 18, 18, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 18, 18, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 18, 18, 128)  114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 18, 18, 128)  114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 18, 18, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 18, 18, 128)  384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 18, 18, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 18, 18, 128)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 18, 18, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 18, 18, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 18, 18, 192)  172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 18, 18, 192)  172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 18, 18, 192)  147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 18, 18, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 18, 18, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 18, 18, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 18, 18, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 18, 18, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 18, 18, 192)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 18, 18, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 18, 18, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 18, 18, 768)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 18, 18, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 18, 18, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 18, 18, 160)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 18, 18, 160)  179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 18, 18, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 18, 18, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 18, 18, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 18, 18, 160)  179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 18, 18, 160)  480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 18, 18, 160)  480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 18, 18, 160)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 18, 18, 160)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 18, 18, 160)  179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 18, 18, 160)  179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 18, 18, 160)  480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 18, 18, 160)  480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 18, 18, 160)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 18, 18, 160)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 18, 18, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 18, 18, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 18, 18, 192)  215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 18, 18, 192)  215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 18, 18, 192)  147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 18, 18, 192)  576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 18, 18, 192)  576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 18, 18, 192)  576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 18, 18, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 18, 18, 192)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 18, 18, 192)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 18, 18, 192)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 18, 18, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 18, 18, 768)  0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 18, 18, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 18, 18, 160)  480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 18, 18, 160)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 18, 18, 160)  179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 18, 18, 160)  480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 18, 18, 160)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 18, 18, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 18, 18, 160)  179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 18, 18, 160)  480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 18, 18, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 18, 18, 160)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 18, 18, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 18, 18, 160)  179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 18, 18, 160)  179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 18, 18, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 18, 18, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 18, 18, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 18, 18, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 18, 18, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 18, 18, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 18, 18, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 18, 18, 192)  215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 18, 18, 192)  147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 18, 18, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 18, 18, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 18, 18, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 18, 18, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 18, 18, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 18, 18, 192)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 18, 18, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 18, 18, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 18, 18, 768)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 18, 18, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 18, 18, 192)  576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 18, 18, 192)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 18, 18, 192)  258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 18, 18, 192)  576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 18, 18, 192)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 18, 18, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 18, 18, 192)  258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 18, 18, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 18, 18, 192)  576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 18, 18, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 18, 18, 192)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 18, 18, 192)  258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 18, 18, 192)  258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 18, 18, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 18, 18, 192)  576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 18, 18, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 18, 18, 192)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 18, 18, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 18, 18, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 18, 18, 192)  258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 18, 18, 192)  258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 18, 18, 192)  147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 18, 18, 192)  576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 18, 18, 192)  576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 18, 18, 192)  576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 18, 18, 192)  576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 18, 18, 192)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 18, 18, 192)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 18, 18, 192)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 18, 18, 192)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 18, 18, 768)  0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 18, 18, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 18, 18, 192)  576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 18, 18, 192)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 18, 18, 192)  258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 18, 18, 192)  576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 18, 18, 192)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 18, 18, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 18, 18, 192)  258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 18, 18, 192)  576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 18, 18, 192)  576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 18, 18, 192)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 18, 18, 192)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 8, 8, 320)    552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 192)    331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 8, 8, 320)    960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 8, 8, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 8, 8, 320)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 8, 8, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 8, 8, 448)    1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 8, 8, 448)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 8, 8, 384)    1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 8, 8, 384)    1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 8, 8, 384)    1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 8, 8, 384)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 8, 8, 384)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 8, 8, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 8, 8, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 8, 8, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 8, 8, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 8, 8, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 8, 8, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 320)    960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 8, 8, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 8, 8, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 8, 8, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 8, 8, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 8, 8, 192)    576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 320)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 8, 8, 192)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 8, 8, 448)    1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 8, 8, 448)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 8, 8, 384)    1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 8, 8, 384)    1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 8, 8, 384)    1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 8, 8, 384)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 8, 8, 384)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 8, 8, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 8, 8, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 8, 8, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 8, 8, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 8, 8, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 8, 8, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 8, 8, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 8, 8, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 8, 8, 320)    960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 8, 8, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 8, 8, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 8, 8, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 8, 8, 320)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 768)    0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 2, 2, 2048)   0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8192)         0           average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          2097408     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            514         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,900,706\n",
      "Trainable params: 23,866,274\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs= 100\n",
    "lr = 1e-4\n",
    "BS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=lr,decay=lr/epochs),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath=\"best_covid19_imporoved2.h5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "# callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM INITIALIZATION OF WEIGHTS\n",
    "class_weight = {\n",
    "    0:0.85,\n",
    "    1:0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 14s 694ms/step - loss: 0.1090 - accuracy: 0.9500 - val_loss: 5.3353 - val_accuracy: 0.7308\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 12s 594ms/step - loss: 0.0276 - accuracy: 0.9844 - val_loss: 4.7414 - val_accuracy: 0.7308\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 13s 674ms/step - loss: 0.0165 - accuracy: 0.9875 - val_loss: 4.1903 - val_accuracy: 0.7308\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 12s 591ms/step - loss: 0.0245 - accuracy: 0.9812 - val_loss: 2.8038 - val_accuracy: 0.7308\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 13s 661ms/step - loss: 0.0108 - accuracy: 0.9841 - val_loss: 0.7999 - val_accuracy: 0.8462\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 12s 588ms/step - loss: 0.0038 - accuracy: 0.9936 - val_loss: 0.3615 - val_accuracy: 0.7692\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 11s 556ms/step - loss: 0.0030 - accuracy: 0.9906 - val_loss: 0.2830 - val_accuracy: 0.8462\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 12s 593ms/step - loss: 0.0169 - accuracy: 0.9906 - val_loss: 0.3075 - val_accuracy: 0.8462\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 11s 563ms/step - loss: 0.0057 - accuracy: 0.9875 - val_loss: 0.3107 - val_accuracy: 0.8462\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 12s 608ms/step - loss: 0.0043 - accuracy: 0.9969 - val_loss: 0.4665 - val_accuracy: 0.8462\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 11s 561ms/step - loss: 0.0196 - accuracy: 0.9875 - val_loss: 0.6340 - val_accuracy: 0.8462\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 11s 572ms/step - loss: 0.0141 - accuracy: 0.9745 - val_loss: 0.4369 - val_accuracy: 0.8846\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 12s 583ms/step - loss: 0.0049 - accuracy: 0.9875 - val_loss: 0.4020 - val_accuracy: 0.8462\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 12s 618ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.8333 - val_accuracy: 0.8077\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 13s 633ms/step - loss: 0.0044 - accuracy: 0.9937 - val_loss: 0.8621 - val_accuracy: 0.8077\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 12s 581ms/step - loss: 0.0094 - accuracy: 0.9844 - val_loss: 0.7792 - val_accuracy: 0.8846\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 11s 553ms/step - loss: 0.0070 - accuracy: 0.9875 - val_loss: 0.7395 - val_accuracy: 0.8846\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 12s 606ms/step - loss: 0.0045 - accuracy: 0.9937 - val_loss: 0.7732 - val_accuracy: 0.8846\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 13s 665ms/step - loss: 0.0049 - accuracy: 0.9875 - val_loss: 0.5800 - val_accuracy: 0.8846\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 11s 572ms/step - loss: 0.0189 - accuracy: 0.9812 - val_loss: 0.6423 - val_accuracy: 0.8846\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 12s 610ms/step - loss: 0.0057 - accuracy: 0.9875 - val_loss: 0.5291 - val_accuracy: 0.8462\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 11s 537ms/step - loss: 0.0047 - accuracy: 0.9937 - val_loss: 0.6344 - val_accuracy: 0.8846\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 11s 550ms/step - loss: 0.0037 - accuracy: 0.9906 - val_loss: 0.7102 - val_accuracy: 0.8462\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 11s 558ms/step - loss: 0.0036 - accuracy: 0.9969 - val_loss: 0.7850 - val_accuracy: 0.8846\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 12s 584ms/step - loss: 0.0069 - accuracy: 0.9844 - val_loss: 0.5700 - val_accuracy: 0.8846\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 11s 560ms/step - loss: 0.0047 - accuracy: 0.9906 - val_loss: 0.8279 - val_accuracy: 0.8846\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 11s 550ms/step - loss: 0.0044 - accuracy: 0.9906 - val_loss: 0.6201 - val_accuracy: 0.8846\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 12s 582ms/step - loss: 0.0083 - accuracy: 0.9844 - val_loss: 0.7922 - val_accuracy: 0.8846\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 11s 550ms/step - loss: 0.0038 - accuracy: 0.9906 - val_loss: 0.7945 - val_accuracy: 0.8846\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 12s 607ms/step - loss: 0.0151 - accuracy: 0.9906 - val_loss: 0.6320 - val_accuracy: 0.8846\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 12s 580ms/step - loss: 0.0101 - accuracy: 0.9750 - val_loss: 0.4003 - val_accuracy: 0.8846\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 12s 588ms/step - loss: 0.0062 - accuracy: 0.9875 - val_loss: 0.4621 - val_accuracy: 0.8846\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 12s 612ms/step - loss: 0.0030 - accuracy: 0.9906 - val_loss: 0.5972 - val_accuracy: 0.8846\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 12s 602ms/step - loss: 0.0034 - accuracy: 0.9969 - val_loss: 0.7083 - val_accuracy: 0.8846\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 11s 532ms/step - loss: 0.0046 - accuracy: 0.9906 - val_loss: 0.5204 - val_accuracy: 0.8846\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 11s 561ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.5494 - val_accuracy: 0.8846\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 11s 540ms/step - loss: 0.0089 - accuracy: 0.9719 - val_loss: 0.5082 - val_accuracy: 0.8846\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 11s 565ms/step - loss: 0.0035 - accuracy: 0.9906 - val_loss: 0.5087 - val_accuracy: 0.8462\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 12s 585ms/step - loss: 0.0031 - accuracy: 0.9969 - val_loss: 0.5273 - val_accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 12s 606ms/step - loss: 0.0018 - accuracy: 0.9969 - val_loss: 0.6299 - val_accuracy: 0.8846\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 11s 565ms/step - loss: 0.0056 - accuracy: 0.9904 - val_loss: 0.5636 - val_accuracy: 0.8846\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 11s 562ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6343 - val_accuracy: 0.8846\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 11s 564ms/step - loss: 0.0036 - accuracy: 0.9937 - val_loss: 1.3143 - val_accuracy: 0.8462\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 11s 571ms/step - loss: 0.0038 - accuracy: 0.9875 - val_loss: 0.7954 - val_accuracy: 0.8846\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 12s 582ms/step - loss: 0.0030 - accuracy: 0.9969 - val_loss: 0.5297 - val_accuracy: 0.8846\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 11s 553ms/step - loss: 0.0031 - accuracy: 0.9906 - val_loss: 0.4389 - val_accuracy: 0.8846\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 11s 533ms/step - loss: 0.0020 - accuracy: 0.9969 - val_loss: 0.3473 - val_accuracy: 0.8846\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 13s 628ms/step - loss: 0.0041 - accuracy: 0.9969 - val_loss: 0.5706 - val_accuracy: 0.9231\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 12s 585ms/step - loss: 0.0039 - accuracy: 0.9937 - val_loss: 0.5763 - val_accuracy: 0.9231\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 11s 556ms/step - loss: 5.3927e-04 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.9231\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 11s 561ms/step - loss: 8.8029e-05 - accuracy: 1.0000 - val_loss: 0.6307 - val_accuracy: 0.9231\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 11s 567ms/step - loss: 0.0022 - accuracy: 0.9969 - val_loss: 0.7524 - val_accuracy: 0.9231\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 11s 561ms/step - loss: 0.0045 - accuracy: 0.9906 - val_loss: 0.6183 - val_accuracy: 0.8846\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 12s 601ms/step - loss: 4.2936e-04 - accuracy: 1.0000 - val_loss: 0.6000 - val_accuracy: 0.9231\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 11s 550ms/step - loss: 8.5941e-05 - accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 0.9231\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 12s 612ms/step - loss: 0.0036 - accuracy: 0.9968 - val_loss: 0.6248 - val_accuracy: 0.9231\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 11s 572ms/step - loss: 0.0011 - accuracy: 0.9969 - val_loss: 0.6481 - val_accuracy: 0.9231\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 11s 546ms/step - loss: 5.3908e-04 - accuracy: 0.9969 - val_loss: 0.6684 - val_accuracy: 0.9231\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 14s 692ms/step - loss: 3.3004e-04 - accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.9231\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 12s 595ms/step - loss: 0.0126 - accuracy: 0.9812 - val_loss: 0.7381 - val_accuracy: 0.8846\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 11s 529ms/step - loss: 0.0181 - accuracy: 0.9875 - val_loss: 0.3762 - val_accuracy: 0.8462\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 11s 562ms/step - loss: 0.0039 - accuracy: 0.9906 - val_loss: 0.5263 - val_accuracy: 0.8462\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 12s 598ms/step - loss: 0.0011 - accuracy: 0.9969 - val_loss: 0.6615 - val_accuracy: 0.8462\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 12s 599ms/step - loss: 0.0051 - accuracy: 0.9937 - val_loss: 0.5516 - val_accuracy: 0.8462\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 11s 575ms/step - loss: 0.0023 - accuracy: 0.9937 - val_loss: 0.5966 - val_accuracy: 0.8462\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 11s 543ms/step - loss: 0.0013 - accuracy: 0.9969 - val_loss: 0.7531 - val_accuracy: 0.8846\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 11s 572ms/step - loss: 1.8465e-04 - accuracy: 1.0000 - val_loss: 0.8096 - val_accuracy: 0.8846\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 12s 596ms/step - loss: 0.0082 - accuracy: 0.9873 - val_loss: 0.5871 - val_accuracy: 0.8077\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 12s 579ms/step - loss: 2.9884e-04 - accuracy: 1.0000 - val_loss: 0.6750 - val_accuracy: 0.8462\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 12s 582ms/step - loss: 0.0250 - accuracy: 0.9906 - val_loss: 0.6686 - val_accuracy: 0.8462\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 13s 649ms/step - loss: 0.0169 - accuracy: 0.9656 - val_loss: 3.0551 - val_accuracy: 0.8077\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 13s 665ms/step - loss: 0.0134 - accuracy: 0.9906 - val_loss: 0.8698 - val_accuracy: 0.8462\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 12s 622ms/step - loss: 0.0096 - accuracy: 0.9719 - val_loss: 0.6969 - val_accuracy: 0.8846\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 12s 611ms/step - loss: 0.0026 - accuracy: 0.9969 - val_loss: 1.0662 - val_accuracy: 0.8846\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 12s 584ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 1.5641 - val_accuracy: 0.7692\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 12s 576ms/step - loss: 0.0091 - accuracy: 0.9781 - val_loss: 0.5330 - val_accuracy: 0.8462\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 12s 592ms/step - loss: 0.0053 - accuracy: 0.9937 - val_loss: 0.5316 - val_accuracy: 0.8846\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 11s 567ms/step - loss: 0.0074 - accuracy: 0.9906 - val_loss: 1.0734 - val_accuracy: 0.8846\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 12s 579ms/step - loss: 0.0108 - accuracy: 0.9844 - val_loss: 0.5917 - val_accuracy: 0.8846\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 11s 570ms/step - loss: 0.0035 - accuracy: 0.9969 - val_loss: 0.4681 - val_accuracy: 0.8462\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 13s 641ms/step - loss: 0.0061 - accuracy: 0.9906 - val_loss: 0.6851 - val_accuracy: 0.8846\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 12s 595ms/step - loss: 0.0026 - accuracy: 0.9969 - val_loss: 0.5988 - val_accuracy: 0.8846\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 12s 599ms/step - loss: 0.0070 - accuracy: 0.9873 - val_loss: 0.6536 - val_accuracy: 0.8846\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 13s 634ms/step - loss: 0.0029 - accuracy: 0.9969 - val_loss: 0.7022 - val_accuracy: 0.8846\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 11s 545ms/step - loss: 0.0024 - accuracy: 0.9969 - val_loss: 0.8437 - val_accuracy: 0.8846\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 11s 575ms/step - loss: 0.0029 - accuracy: 0.9969 - val_loss: 0.8152 - val_accuracy: 0.8846\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 11s 568ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.9673 - val_accuracy: 0.8846\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 11s 571ms/step - loss: 0.0041 - accuracy: 0.9906 - val_loss: 0.6023 - val_accuracy: 0.8846\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 13s 629ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.8490 - val_accuracy: 0.8846\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 11s 571ms/step - loss: 0.0079 - accuracy: 0.9781 - val_loss: 0.7065 - val_accuracy: 0.8846\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 12s 597ms/step - loss: 0.0048 - accuracy: 0.9906 - val_loss: 0.6336 - val_accuracy: 0.8846\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 12s 589ms/step - loss: 4.2553e-04 - accuracy: 1.0000 - val_loss: 0.7409 - val_accuracy: 0.8846\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 12s 596ms/step - loss: 0.0038 - accuracy: 0.9937 - val_loss: 0.7166 - val_accuracy: 0.8846\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 12s 609ms/step - loss: 0.0018 - accuracy: 0.9969 - val_loss: 0.5840 - val_accuracy: 0.8846\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 11s 540ms/step - loss: 0.0021 - accuracy: 0.9969 - val_loss: 0.6400 - val_accuracy: 0.8462\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 12s 605ms/step - loss: 0.0154 - accuracy: 0.9812 - val_loss: 0.7709 - val_accuracy: 0.8846\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 13s 637ms/step - loss: 0.0021 - accuracy: 0.9937 - val_loss: 0.3569 - val_accuracy: 0.8846\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 13s 638ms/step - loss: 0.0042 - accuracy: 0.9969 - val_loss: 0.4742 - val_accuracy: 0.8846\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 11s 541ms/step - loss: 0.0012 - accuracy: 0.9969 - val_loss: 0.5721 - val_accuracy: 0.8846\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 11s 544ms/step - loss: 0.0021 - accuracy: 0.9937 - val_loss: 0.4963 - val_accuracy: 0.8846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f13f8c0f710>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = 320//BS,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = 26,\n",
    "                   class_weight=class_weight\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_generator, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 17,   2],\n",
       "       [  3, 628]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cm=confusion_matrix(test_generator.classes,predictions)\n",
    "# def plot_confusion_matrix(cm, classes,\n",
    "#     normalize=False,\n",
    "#     title='Confusion matrix',\n",
    "#     cmap=plt.cm.Blues):\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "    \n",
    "#     fmt = '.2f' if normalize else 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         plt.text(j, i, format(cm[i, j], fmt),\n",
    "#                  horizontalalignment=\"center\",\n",
    "#                  color=\"red\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.show()\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "cm=confusion_matrix(test_generator.classes, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_generator.classes, y_pred)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for COVID19 classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     COVID19       0.85      0.89      0.87        19\n",
      "      OTHERS       1.00      1.00      1.00       631\n",
      "\n",
      "    accuracy                           0.99       650\n",
      "   macro avg       0.92      0.94      0.93       650\n",
      "weighted avg       0.99      0.99      0.99       650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "target_names = ['COVID19','OTHERS']\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
