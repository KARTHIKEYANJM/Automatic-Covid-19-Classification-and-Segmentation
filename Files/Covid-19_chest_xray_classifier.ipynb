{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the needed packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU') \n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout,Flatten, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix,plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import os\n",
    "import itertools\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D, Add, Activation, Multiply, concatenate\n",
    "from tensorflow.keras.applications import VGG16,DenseNet201,ResNet50,VGG19,Xception,InceptionResNetV2,InceptionV3\n",
    "from tensorflow.keras.layers import AveragePooling2D,MaxPooling2D,GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='../input/newdataset/final_dataset/train'\n",
    "test_path='../input/newdataset/final_dataset/test'\n",
    "val_path='../input/newdataset/final_dataset/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_path,target_size = (320, 320),shuffle=True,seed=42,class_mode=\"categorical\",color_mode = 'rgb',batch_size = 16)\n",
    "test_generator = test_datagen.flow_from_directory(test_path,target_size = (320, 320),color_mode = 'rgb',batch_size = 1,seed=42,class_mode=\"categorical\",shuffle = False)\n",
    "val_generator = test_datagen.flow_from_directory(val_path,target_size = (320, 320),color_mode = 'rgb',batch_size = 1,seed=42,class_mode=\"categorical\",shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting of Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img_arr):\n",
    "  fig,axes=plt.subplots(2,8,figsize=(10,10))\n",
    "  axes=axes.flatten()\n",
    "  for img,ax in zip(img_arr,axes):\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,labels=next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM INITIALIZATION OF WEIGHTS\n",
    "class_weight = {\n",
    "    0:0.85,\n",
    "    1:0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "EPOCHS = 100\n",
    "BS = 16\n",
    "k_fold=2\n",
    "cv_scores, model_history = list(), list()\n",
    "for i in range(k_fold):\n",
    "    \n",
    "    print(\"K-FOLD:\",i+1)\n",
    "    baseModel = ResNet50(include_top=False,weights='imagenet',input_tensor=Input(shape=(320, 320, 3)))\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(4, 4))(headModel)#pool_size=(4, 4)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.3)(headModel)\n",
    "    headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = Adam(lr=lr,decay=lr/EPOCHS)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "    print(\"[INFO] training head...\")\n",
    "    H = model.fit(train_generator,\n",
    "                    steps_per_epoch = 320//BS,\n",
    "                    epochs = EPOCHS,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = 26,\n",
    "                   class_weight=class_weight)\n",
    "    predictions=model.predict(test_generator,use_multiprocessing=True)\n",
    "    predIdxs = np.argmax(predictions, axis=1)\n",
    "    cm=confusion_matrix(y_true=test_generator.classes,y_pred=predIdxs)\n",
    "    print(cm)\n",
    "    print(classification_report(test_generator.classes,predIdxs))\n",
    "    total = sum(sum(cm))\n",
    "    acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "    sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    # show the confusion matrix, accuracy, sensitivity, and specificity\n",
    "    print(cm)\n",
    "    print(\"acc: {:.4f}\".format(acc))\n",
    "    print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "    print(\"specificity: {:.4f}\".format(specificity))\n",
    "\n",
    "    cv_scores.append(acc)\n",
    "    model_history.append(H.history)\n",
    "\n",
    "print('Estimated Accuracy %.3f (%.3f)' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_generator.classes, predIdxs)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for COVID19 classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "EPOCHS = 100\n",
    "BS = 16\n",
    "k_fold=2\n",
    "cv_scores, model_history = list(), list()\n",
    "for i in range(k_fold):\n",
    "    \n",
    "    print(\"K-FOLD:\",i+1)\n",
    "    baseModel = VGG19(include_top=False,weights='imagenet',input_tensor=Input(shape=(320, 320, 3)))\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(4, 4))(headModel)#pool_size=(4, 4)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.3)(headModel)\n",
    "    headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = Adam(lr=lr,decay=lr/EPOCHS)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "    print(\"[INFO] training head...\")\n",
    "    H = model.fit(train_generator,\n",
    "                    steps_per_epoch = 320//BS,\n",
    "                    epochs = EPOCHS,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = 26,\n",
    "                   class_weight=class_weight)\n",
    "    predictions=model.predict(test_generator,use_multiprocessing=True)\n",
    "    predIdxs = np.argmax(predictions, axis=1)\n",
    "    cm=confusion_matrix(y_true=test_generator.classes,y_pred=predIdxs)\n",
    "    print(cm)\n",
    "    print(classification_report(test_generator.classes,predIdxs))\n",
    "    total = sum(sum(cm))\n",
    "    acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "    sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    # show the confusion matrix, accuracy, sensitivity, and specificity\n",
    "    print(cm)\n",
    "    print(\"acc: {:.4f}\".format(acc))\n",
    "    print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "    print(\"specificity: {:.4f}\".format(specificity))\n",
    "\n",
    "    cv_scores.append(acc)\n",
    "    model_history.append(H.history)\n",
    "\n",
    "print('Estimated Accuracy %.3f (%.3f)' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_generator.classes, predIdxs)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for COVID19 classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "EPOCHS = 100\n",
    "BS = 16\n",
    "k_fold=2\n",
    "cv_scores, model_history = list(), list()\n",
    "for i in range(k_fold):\n",
    "    \n",
    "    print(\"K-FOLD:\",i+1)\n",
    "    baseModel = VGG16(include_top=False,weights='imagenet',input_tensor=Input(shape=(320, 320, 3)))\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(4, 4))(headModel)#pool_size=(4, 4)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.3)(headModel)\n",
    "    headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = Adam(lr=lr,decay=lr/EPOCHS)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "    print(\"[INFO] training head...\")\n",
    "    H = model.fit(train_generator,\n",
    "                    steps_per_epoch = 320//BS,\n",
    "                    epochs = EPOCHS,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = 26,\n",
    "                   class_weight=class_weight)\n",
    "    predictions=model.predict(test_generator,use_multiprocessing=True)\n",
    "    predIdxs = np.argmax(predictions, axis=1)\n",
    "    cm=confusion_matrix(y_true=test_generator.classes,y_pred=predIdxs)\n",
    "    print(cm)\n",
    "    print(classification_report(test_generator.classes,predIdxs))\n",
    "    total = sum(sum(cm))\n",
    "    acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "    sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    # show the confusion matrix, accuracy, sensitivity, and specificity\n",
    "    print(cm)\n",
    "    print(\"acc: {:.4f}\".format(acc))\n",
    "    print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "    print(\"specificity: {:.4f}\".format(specificity))\n",
    "\n",
    "    cv_scores.append(acc)\n",
    "    model_history.append(H.history)\n",
    "\n",
    "print('Estimated Accuracy %.3f (%.3f)' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_generator.classes, predIdxs)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for COVID19 classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "EPOCHS = 100\n",
    "BS = 16\n",
    "k_fold=2\n",
    "cv_scores, model_history = list(), list()\n",
    "for i in range(k_fold):\n",
    "    \n",
    "    print(\"K-FOLD:\",i+1)\n",
    "    baseModel = Xception(include_top=False,weights='imagenet',input_tensor=Input(shape=(320, 320, 3)))\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(4, 4))(headModel)#pool_size=(4, 4)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.3)(headModel)\n",
    "    headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = Adam(lr=lr,decay=lr/EPOCHS)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "    print(\"[INFO] training head...\")\n",
    "    H = model.fit(train_generator,\n",
    "                    steps_per_epoch = 320//BS,\n",
    "                    epochs = EPOCHS,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = 26,\n",
    "                   class_weight=class_weight)\n",
    "    predictions=model.predict(test_generator,use_multiprocessing=True)\n",
    "    predIdxs = np.argmax(predictions, axis=1)\n",
    "    cm=confusion_matrix(y_true=test_generator.classes,y_pred=predIdxs)\n",
    "    print(cm)\n",
    "    print(classification_report(test_generator.classes,predIdxs))\n",
    "    total = sum(sum(cm))\n",
    "    acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "    sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    # show the confusion matrix, accuracy, sensitivity, and specificity\n",
    "    print(cm)\n",
    "    print(\"acc: {:.4f}\".format(acc))\n",
    "    print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "    print(\"specificity: {:.4f}\".format(specificity))\n",
    "\n",
    "    cv_scores.append(acc)\n",
    "    model_history.append(H.history)\n",
    "\n",
    "print('Estimated Accuracy %.3f (%.3f)' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_generator.classes, predIdxs)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for COVID19 classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "EPOCHS = 100\n",
    "BS = 16\n",
    "k_fold=2\n",
    "cv_scores, model_history = list(), list()\n",
    "for i in range(k_fold):\n",
    "    \n",
    "    print(\"K-FOLD:\",i+1)\n",
    "    baseModel = DenseNet201(include_top=False,weights='imagenet',input_tensor=Input(shape=(320, 320, 3)))\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(4, 4))(headModel)#pool_size=(4, 4)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.3)(headModel)\n",
    "    headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = Adam(lr=lr,decay=lr/EPOCHS)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "    print(\"[INFO] training head...\")\n",
    "    H = model.fit(train_generator,\n",
    "                    steps_per_epoch = 320//BS,\n",
    "                    epochs = EPOCHS,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = 26,\n",
    "                   class_weight=class_weight)\n",
    "    predictions=model.predict(test_generator,use_multiprocessing=True)\n",
    "    predIdxs = np.argmax(predictions, axis=1)\n",
    "    cm=confusion_matrix(y_true=test_generator.classes,y_pred=predIdxs)\n",
    "    print(cm)\n",
    "    print(classification_report(test_generator.classes,predIdxs))\n",
    "    total = sum(sum(cm))\n",
    "    acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "    sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    # show the confusion matrix, accuracy, sensitivity, and specificity\n",
    "    print(cm)\n",
    "    print(\"acc: {:.4f}\".format(acc))\n",
    "    print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "    print(\"specificity: {:.4f}\".format(specificity))\n",
    "\n",
    "    cv_scores.append(acc)\n",
    "    model_history.append(H.history)\n",
    "\n",
    "print('Estimated Accuracy %.3f (%.3f)' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_generator.classes, predIdxs)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for COVID19 classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "EPOCHS = 100\n",
    "BS = 16\n",
    "k_fold=2\n",
    "cv_scores, model_history = list(), list()\n",
    "for i in range(k_fold):\n",
    "    \n",
    "    print(\"K-FOLD:\",i+1)\n",
    "    baseModel = InceptionResNetV2(include_top=False,weights='imagenet',input_tensor=Input(shape=(320, 320, 3)))\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(4, 4))(headModel)#pool_size=(4, 4)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.3)(headModel)\n",
    "    headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = Adam(lr=lr,decay=lr/EPOCHS)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "    print(\"[INFO] training head...\")\n",
    "    H = model.fit(train_generator,\n",
    "                    steps_per_epoch = 320//BS,\n",
    "                    epochs = EPOCHS,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = 26,\n",
    "                   class_weight=class_weight)\n",
    "    predictions=model.predict(test_generator,use_multiprocessing=True)\n",
    "    predIdxs = np.argmax(predictions, axis=1)\n",
    "    cm=confusion_matrix(y_true=test_generator.classes,y_pred=predIdxs)\n",
    "    print(cm)\n",
    "    print(classification_report(test_generator.classes,predIdxs))\n",
    "    total = sum(sum(cm))\n",
    "    acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "    sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    # show the confusion matrix, accuracy, sensitivity, and specificity\n",
    "    print(cm)\n",
    "    print(\"acc: {:.4f}\".format(acc))\n",
    "    print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "    print(\"specificity: {:.4f}\".format(specificity))\n",
    "\n",
    "    cv_scores.append(acc)\n",
    "    model_history.append(H.history)\n",
    "\n",
    "print('Estimated Accuracy %.3f (%.3f)' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_generator.classes, predIdxs)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for COVID19 classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
